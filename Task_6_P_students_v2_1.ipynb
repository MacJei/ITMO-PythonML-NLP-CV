{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQp47ajD2Ga4"
      },
      "source": [
        "# Знакомство с word2vec\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04UILL-kiKYc",
        "outputId": "5bc9c139-eb87-4435-de37-3c2fd186c4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq_WfHCAiKhG",
        "outputId": "31be4fdf-c071-4994-f108-478be12292e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 37.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_Pat15ls9N8"
      },
      "source": [
        "## Загрузка модели\n",
        "Скачаем модель <code>google-news-vectors</code>. Откроем ее с помощью библиотеки <code>gensim</code>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd-xNyAGy1tT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7608bc1-49ed-4067-9117-93b31e1924be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "From (redirected): https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&confirm=t&uuid=2c370937-095d-4842-91fe-9a75caafac35\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "100% 1.65G/1.65G [00:10<00:00, 156MB/s]\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.2/25.2 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade --no-cache-dir gdown\n",
        "! pip install -q -U gensim\n",
        "! gdown --id 0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
        "! pip install -q SciPy==1.5.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "metadata": {
        "id": "t9CnRiM9kL8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4xfcycMynhZ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "w = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\",\n",
        "                                      binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6JtQjaORfzA"
      },
      "source": [
        "Структура называется <code>KeyedVectors</code> и по сути представляет собой отображение между ключами и векторами. Каждый вектор идентифицируется своим ключом поиска, чаще всего коротким строковым токеном, поэтому обычно это соответствие между\n",
        "\n",
        "<center><code>{str => 1D numpy array}</code></center><br/>\n",
        "\n",
        "\n",
        "\n",
        "Например, выведем первые 10 координат вектора, соответствующего слову <code>sunrise</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol9DuE6VRfzH",
        "outputId": "09eadd0d-0c47-4fe5-9923-6f1864b2bcdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность вектора:  (300,)\n",
            "Первые 10 координат вектора: \n",
            " [-0.22558594 -0.03540039 -0.21679688  0.03613281 -0.2265625  -0.09814453\n",
            "  0.109375   -0.34570312  0.18652344  0.01806641]\n"
          ]
        }
      ],
      "source": [
        "print(\"Размерность вектора: \", w[\"sunrise\"].shape)\n",
        "print(\"Первые 10 координат вектора: \\n\", w[\"sunrise\"][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rv9Rqvq2af8"
      },
      "source": [
        "## Задание 1. Сходство."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mns8gpJFRfzd"
      },
      "source": [
        "Извлеките векторы слов <code>London</code>, <code>England</code>, <code>Moscow</code>. Посчитайте косинусное расстояние между словами <code>London</code> и <code>England</code> и между словами <code>Moscow</code> и <code>England</code>. Какая пара слов ближе? Подсказка: для вычисления косинусного расстояния использвется метод <code>distance()</code>. Правильный ответ представлен в блоке вывода."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "vec_london = w[\"London\"]\n",
        "vec_england = w[\"England\"]\n",
        "vec_moscow = w[\"Moscow\"]\n",
        "\n",
        "print(\"Cosine distance between London and England: \", float(distance.cosine(vec_london, vec_england)))\n",
        "print(\"Cosine distance between Moscow and England: \", float(distance.cosine(vec_moscow, vec_england)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0d0PqQ8uo9L",
        "outputId": "afc96dcb-d33e-4494-fe55-d0167a2460f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine distance between London and England:  0.5600714087486267\n",
            "Cosine distance between Moscow and England:  0.8476868271827698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLXEcSxt3DG4"
      },
      "source": [
        "## Задание 2. Аналогии.\n",
        "С помощью метода most_similar решите аналогию\n",
        "```London : England = Moscow : X```\n",
        "\n",
        "Правильный ответ представлен в блоке вывода.\n",
        "\n",
        "(Подсказка: нужно использовать аргументы positive и negative)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.most_similar(positive=[vec_moscow, \"Russia\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9rt6-kyHojU",
        "outputId": "6a31b9fa-15b2-4326-c332-da7ed95a7722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Moscow', 0.98638916015625),\n",
              " ('Kremlin', 0.7748246192932129),\n",
              " ('Russian', 0.7569824457168579),\n",
              " ('Kiev', 0.7495608329772949),\n",
              " ('Tbilisi', 0.7209931015968323),\n",
              " ('Minsk', 0.7206584215164185),\n",
              " ('Ukraine', 0.71128249168396),\n",
              " ('Kyiv', 0.7099266648292542),\n",
              " ('St_Petersburg', 0.6833096742630005),\n",
              " ('Tashkent', 0.6815599203109741)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzneqrn3Djq"
      },
      "source": [
        "\n",
        "## Задание 3. Сходство: найти лишнее.\n",
        "С помощью метода <code>doesnt_match</code> найдите лишнее слово в ряду <code>breakfast cereal dinner lunch</code>.\n",
        "\n",
        "Правильный ответ представлен в блоке вывода."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str = \"breakfast cereal dinner lunch\"\n",
        "\n",
        "extra_words = w.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
        "\n",
        "print(\"Лишнее слово: \", extra_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1wVvLfsO1HH",
        "outputId": "2c932525-d672-4e4d-c59d-9a091f32b65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лишнее слово:  cereal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT-Zl3YaRf0X"
      },
      "source": [
        "## Задание 4. Представление предложений в виде векторов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm_SiyjU3D9G"
      },
      "source": [
        "\n",
        "Дано предложение: <code>the quick brown fox jumps over the lazy dog</code>. Вам нужно представить это предложение в виде вектора. Для этого найдите вектор каждого слова в модели, а затем усредните векторы покомпонентно.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the sentence\n",
        "sentence = \"the quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Split the sentence into words\n",
        "words = sentence.split()\n",
        "\n",
        "# Get the vector for each word in the sentence\n",
        "vectors = [w[word] for word in words]\n",
        "\n",
        "# Average the vectors component by component\n",
        "sentence_vector = np.average(vectors, axis=0)\n",
        "\n",
        "# Print the first 5 coordinates of the sentence vector\n",
        "print(sentence_vector[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YOGMZjdShnI",
        "outputId": "f5d12fa1-0c1f-4183-80e3-64a780a9ce2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.09055582  0.05434163 -0.06713867  0.10968696 -0.01060655]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-HvrEkHtFqQ"
      },
      "source": [
        "## Загрузка ещё одной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z13Io-4x3Ve2"
      },
      "source": [
        "\n",
        "Откроем модель google-news-vectors и модель, обученную на британском национальном корпусе http://vectors.nlpl.eu/repository/20/0.zip, с помощью gensim.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QPYDnlz3X2B",
        "outputId": "afd6d9de-c37e-488d-d490-08e784cfbd2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-11 17:51:46--  http://vectors.nlpl.eu/repository/20/0.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 344050746 (328M) [application/zip]\n",
            "Saving to: ‘0.zip’\n",
            "\n",
            "0.zip               100%[===================>] 328.11M  22.9MB/s    in 15s     \n",
            "\n",
            "2023-06-11 17:52:02 (21.6 MB/s) - ‘0.zip’ saved [344050746/344050746]\n",
            "\n",
            "Archive:  0.zip\n",
            "  inflating: meta.json               \n",
            "  inflating: model.bin               \n",
            "  inflating: model.txt               \n",
            "  inflating: README                  \n",
            "163473 300\n",
            "say_VERB -0.008861 0.097097 0.100236 0.070044 -0.079279 0.000923 -0.012829 0.064301 -0.029405 -0.009858 -0.017753 0.063115 0.033623 0.019805 0.052704 -0.100458 0.089387 -0.040792 -0.088936 0.110212 -0.044749 0.077675 -0.017062 -0.063745 -0.009502 -0.079371 0.066952 -0.070209 0.063761 -0.038194 -0.046252 0.049983 -0.094985 -0.086341 0.024665 -0.112857 -0.038358 -0.007008 -0.010063 -0.000183 0.068841 0.024942 -0.042561 -0.044576 0.010776 0.006323 0.088285 -0.062522 0.028216 0.088291 0.033231 -0.033732 -0.002995 0.118994 0.000453 0.158588 -0.044475 -0.137629 0.066080 0.062824 -0.128369 -0.087959 0.028080 0.070063 0.046700 -0.083278 -0.118428 0.071118 0.100757 0.017944 0.026296 0.017282 -0.082127 -0.006148 0.002967 -0.032857 -0.076493 -0.072842 -0.055179 -0.081703 0.011437 -0.038698 -0.062540 -0.027899 0.087635 0.031870 0.029164 0.000524 -0.039895 -0.055559 0.024582 -0.030595 0.003942 -0.034500 0.003012 -0.023863 0.033831 0.061476 -0.090183 -0.039206 -0.026586 -0.042763 0.049835 -0.052496 -0.020044 0.073703 0.096775 0.033063 0.000313 -0.022581 -0.141154 0.032095 0.077733 -0.063739 -0.055647 -0.017604 0.044639 -0.062925 -0.001960 0.024665 -0.009416 -0.021381 0.082724 -0.031026 0.027255 0.066198 0.000845 0.008393 0.039434 0.054104 -0.060255 0.034266 0.079435 0.043624 -0.015871 -0.038030 -0.030374 -0.020542 0.007132 0.008708 0.087840 0.017351 -0.089493 0.030182 0.026961 -0.071212 -0.004854 0.007389 0.067203 -0.026351 -0.011460 -0.058723 0.013153 -0.020313 -0.051170 0.002242 0.088222 -0.004267 -0.073523 -0.021874 -0.033585 -0.048553 -0.019119 -0.025310 0.053096 0.111063 0.035042 -0.082811 -0.073749 -0.010048 0.012265 -0.023893 -0.125340 0.026611 0.043258 -0.010473 -0.044428 -0.039251 -0.046891 -0.013008 0.062219 0.078732 -0.086303 0.016901 0.010331 -0.043754 -0.057733 -0.037964 0.024907 0.068143 -0.019992 -0.035030 0.038854 0.034345 -0.048839 -0.105419 0.043013 -0.023374 -0.077629 -0.076465 0.078564 -0.024519 0.041293 -0.032088 -0.007053 0.022618 -0.004657 -0.093970 -0.000199 0.004813 -0.044789 -0.127900 -0.033516 -0.043816 0.033056 -0.057619 0.004901 0.018863 0.039752 0.000739 -0.136350 -0.067819 -0.014856 0.058351 -0.014275 -0.000873 -0.039388 -0.017191 -0.051184 -0.046863 0.006143 -0.075998 -0.064695 0.046676 -0.020558 0.082474 0.160449 -0.027475 0.009541 -0.021876 0.027416 0.078049 0.089309 0.032928 -0.033272 0.048905 0.061164 0.054811 0.024527 -0.034978 -0.018083 -0.077601 0.034112 -0.021121 0.098856 0.019585 -0.058928 -0.016126 -0.011748 0.031588 0.003205 -0.077483 -0.002372 -0.113548 0.047445 -0.027094 -0.032843 0.042378 -0.074703 0.057001 0.012020 0.131156 0.002080 -0.065770 0.112443 0.047786 0.024492 -0.108401 0.016836 0.001478 0.041542 -0.067801 0.102876 -0.052808 -0.136035 0.073852 0.079966 -0.000586 0.034055 -0.053040 0.050461 -0.021550 0.014827 0.077605 -0.024783 -0.082388 0.074410 -0.033689 -0.010982 0.043733\n",
            "go_VERB 0.010490 0.094733 0.143699 0.040344 -0.103710 -0.000016 -0.014351 0.019653 0.069472 -0.046938 -0.057882 0.076405 -0.025230 0.026663 0.029986 -0.001605 -0.027803 0.037521 -0.050608 0.016215 0.025947 0.061172 -0.037448 -0.079232 0.071731 -0.085143 0.021494 -0.135554 -0.026115 -0.066408 0.022858 0.083231 0.020998 -0.049906 -0.079992 -0.060827 -0.028916 -0.029005 0.026067 -0.074869 0.073802 0.023593 -0.024348 -0.093236 0.006169 0.013119 0.007817 -0.088096 -0.012373 0.099807 0.011438 0.028583 0.025614 0.175403 0.007033 0.038856 0.004040 -0.088907 0.079697 0.037448 -0.128230 -0.066502 -0.018969 0.025777 0.035905 0.003710 -0.089079 0.071521 0.039237 0.052136 0.020986 -0.030793 -0.069486 -0.137115 0.008305 0.020813 -0.155342 0.000619 -0.033499 -0.104162 -0.061528 -0.043877 -0.042524 -0.032872 0.045071 0.072908 0.096057 0.141987 -0.078056 -0.013102 -0.026589 -0.073783 0.114807 0.077389 -0.041879 -0.052886 0.053710 0.036806 -0.035973 0.049071 -0.107199 -0.043581 0.016515 -0.029278 -0.026228 0.068037 -0.024183 0.040984 -0.020469 -0.103833 -0.007225 -0.073788 -0.051063 -0.037850 0.052581 -0.053090 -0.012198 -0.057343 0.024050 -0.046498 0.003065 -0.058912 0.043695 0.006340 0.060953 -0.008608 -0.029686 0.081187 -0.020058 0.059240 -0.061306 -0.002190 -0.020671 0.076712 0.049087 0.001153 0.087481 0.008559 0.069936 -0.015886 0.006122 0.038000 -0.071984 0.005263 0.060463 -0.051217 -0.034060 0.045217 0.059163 -0.048462 -0.005371 0.009663 0.081303 0.051019 -0.001248 -0.022637 0.016228 -0.006395 -0.053985 -0.014513 -0.017219 -0.010658 -0.012446 -0.035279 -0.003882 0.036453 0.029681 0.021278 0.006188 0.027861 0.076864 -0.042835 -0.022834 0.013928 0.066150 0.040982 -0.110985 -0.018865 0.006675 0.019173 0.021484 -0.021977 -0.035462 0.000464 -0.024281 0.010881 -0.064037 -0.024893 -0.095968 0.020834 -0.114225 -0.023433 -0.043971 0.014273 0.013481 -0.007542 0.079197 0.021280 -0.129871 0.080770 0.028912 -0.044134 -0.019904 -0.039406 -0.076024 0.058488 -0.094331 -0.082633 0.017676 -0.084006 -0.024444 -0.049778 -0.044615 -0.013499 -0.036736 -0.038579 -0.117319 0.012026 -0.007846 0.024003 -0.101645 0.111720 -0.010241 0.050279 -0.002212 0.060056 -0.116837 0.006078 -0.017954 -0.021794 0.020252 -0.031337 -0.032407 0.081086 -0.095125 0.041699 0.015953 -0.045653 -0.022522 -0.021422 -0.029167 0.052594 0.016523 0.081598 -0.027877 0.000609 0.012837 0.011880 0.074220 0.009736 0.006465 -0.140252 0.010762 -0.038319 0.038924 0.042537 0.005027 0.014024 0.024548 0.050131 -0.048069 -0.012616 -0.052162 -0.100378 0.067741 -0.067824 -0.020692 -0.043022 -0.038036 -0.016860 0.027835 0.140990 -0.045201 -0.069347 0.174518 -0.000236 0.008150 -0.039823 0.041197 0.056322 0.085883 0.027376 0.036537 0.094723 -0.103076 0.105746 0.059074 0.010947 0.099756 -0.027213 0.128793 -0.054593 0.025890 0.053512 0.005200 -0.035256 0.063273 -0.027069 0.046354 -0.002262\n"
          ]
        }
      ],
      "source": [
        "! wget -c http://vectors.nlpl.eu/repository/20/0.zip\n",
        "! unzip 0.zip\n",
        "! head -3 model.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-21wScRRf1E"
      },
      "source": [
        "Загрузим модель, обученную на британском национальном корпусе"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E6OAvhw8-A7"
      },
      "outputs": [],
      "source": [
        "w_british = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7VEcvPIRf1W",
        "outputId": "27fb7172-d2b4-4665-c667-21d99c8e377b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n",
            "lower is ok\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    print(w_british[\"London_NOUN\"].shape)\n",
        "    print('upper is ok')\n",
        "except:\n",
        "    print(w_british[\"london_NOUN\"].shape)\n",
        "    print('lower is ok')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfpohw153YQs"
      },
      "source": [
        "## Набор данных для оценки качества\n",
        "Скачаем датасет wordsim353.\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6c2--gQ3bJF",
        "outputId": "d70369b1-d0e0-41eb-8bcb-865f85b592be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-11 17:52:26--  http://alfonseca.org/pubs/ws353simrel.tar.gz\n",
            "Resolving alfonseca.org (alfonseca.org)... 162.215.249.67\n",
            "Connecting to alfonseca.org (alfonseca.org)|162.215.249.67|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5460 (5.3K) [application/x-gzip]\n",
            "Saving to: ‘ws353simrel.tar.gz’\n",
            "\n",
            "\rws353simrel.tar.gz    0%[                    ]       0  --.-KB/s               \rws353simrel.tar.gz  100%[===================>]   5.33K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-11 17:52:26 (628 MB/s) - ‘ws353simrel.tar.gz’ saved [5460/5460]\n",
            "\n",
            "wordsim353_sim_rel/wordsim353_agreed.txt\n",
            "wordsim353_sim_rel/wordsim353_annotator1.txt\n",
            "wordsim353_sim_rel/wordsim353_annotator2.txt\n",
            "wordsim353_sim_rel/wordsim_relatedness_goldstandard.txt\n",
            "wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\n",
            "tiger\tcat\t7.35\n",
            "tiger\ttiger\t10.00\n",
            "plane\tcar\t5.77\n",
            "train\tcar\t6.31\n",
            "television\tradio\t6.77\n"
          ]
        }
      ],
      "source": [
        "! wget -c http://alfonseca.org/pubs/ws353simrel.tar.gz\n",
        "! tar -xvf ws353simrel.tar.gz\n",
        "! head -5 wordsim353_sim_rel/wordsim_similarity_goldstandard.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Bpeg6FQd3clf",
        "outputId": "4b4335ce-d6c3-48bb-cd03-998740b369b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   first second  score\n",
              "0  tiger    cat   7.35\n",
              "1  tiger  tiger  10.00\n",
              "2  plane    car   5.77"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4fda9f91-9269-45c7-ad01-3526daea43ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first</th>\n",
              "      <th>second</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiger</td>\n",
              "      <td>cat</td>\n",
              "      <td>7.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tiger</td>\n",
              "      <td>tiger</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plane</td>\n",
              "      <td>car</td>\n",
              "      <td>5.77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fda9f91-9269-45c7-ad01-3526daea43ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4fda9f91-9269-45c7-ad01-3526daea43ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4fda9f91-9269-45c7-ad01-3526daea43ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\",\n",
        "                 sep=\"\\t\", header=None)\n",
        "df.columns = [\"first\", \"second\", \"score\"]\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J2LHrp-cuPTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the gold standard similarity scores\n",
        "gold_df = pd.read_csv(\"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\", sep=\"\\t\", header=None)\n",
        "gold_df.columns = [\"first\", \"second\", \"gold_score\"]\n",
        "\n",
        "# Merge the gold standard dataframe with your own scores dataframe\n",
        "merged_df = pd.merge(gold_df, my_scores_df, on=[\"first\", \"second\"])\n",
        "\n",
        "# Calculate the Spearman correlation coefficient between the gold standard scores and your own scores\n",
        "corr, p_value = spearmanr(merged_df[\"gold_score\"], merged_df[\"score\"])\n",
        "print(\"Spearman correlation coefficient:\", corr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "OojckLGAtJpu",
        "outputId": "37ae1dfa-dbed-4ede-faeb-ab465f85cf9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e60327f8949f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Merge the gold standard dataframe with your own scores dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_scores_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"first\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"second\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Calculate the Spearman correlation coefficient between the gold standard scores and your own scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'my_scores_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZlbnwcq-SCL"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Merge with human similarity ratings on word pairs\n",
        "merged_df = pd.merge(df, model_preds, on=[\"first\", \"second\"])\n",
        "\n",
        "# Calculate the Spearman correlation coefficient and p-value\n",
        "corr, pval = spearmanr(merged_df[\"score_x\"], merged_df[\"score_y\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtlAncsQANfx"
      },
      "source": [
        "Можно заметить, что модель google-news-vectors несколько выигрывает в данном случае."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание начинается тут"
      ],
      "metadata": {
        "id": "Cm-Z9TkzyImZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Определите косинусное расстояние между векторами слов: media и bread\n",
        "print(\"Косинусное расстояние GN\", round(w.distance(\"media\", \"bread\"), 3))\n",
        "print(\"Косинусное расстояние BR\", round(w_british.distance(\"media_NOUN\", \"bread_NOUN\"), 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdDMcgJePkRk",
        "outputId": "b1a79ae1-82a4-49fc-def0-b8cfb3509917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Косинусное расстояние GN 0.839\n",
            "Косинусное расстояние BR 0.886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Дан набор слов: media bread cucumber doctor, определите лишнее слово.\n",
        "gn_words = \"media bread cucumber doctor\".split()\n",
        "br_words = list(map(lambda x: x + \"_NOUN\", gn_words))\n",
        "print(br_words)\n",
        "print(\"Лишнее слово GN\", w.doesnt_match(gn_words))\n",
        "print(\"Лишнее слово BR (без _NOUN)\", w_british.doesnt_match(br_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpTIwhYnRgcc",
        "outputId": "bb0ee08f-166a-4a46-96f0-eca2868bb251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['media_NOUN', 'bread_NOUN', 'cucumber_NOUN', 'doctor_NOUN']\n",
            "Лишнее слово GN media\n",
            "Лишнее слово BR (без _NOUN) media_NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Определите косинусное расстояние между векторами предложений:\n",
        "# chain is only as strong as its weakest link\n",
        "# Actions speak louder than words\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#enter your code here\n",
        "# предложение\n",
        "sentence_1 = 'chain is only as strong as its weakest link'\n",
        "sentence_2 = 'Actions speak louder than words'\n",
        "\n",
        "# список слов в предложении\n",
        "words_1 = sentence_1.split()\n",
        "words_2 = sentence_2.split()\n",
        "\n",
        "# получение вектора каждого слова\n",
        "word_vectors_1 = [w[word] for word in words_1]\n",
        "word_vectors_2 = [w[word] for word in words_2]\n",
        "\n",
        "# усреднение векторов слов\n",
        "sentence_vector_1 = np.mean(word_vectors_1, axis=0)\n",
        "sentence_vector_2 = np.mean(word_vectors_2, axis=0)\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "print(\"distance\", round(cosine(sentence_vector_1, sentence_vector_2), 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5mvUFuIRwDM",
        "outputId": "5b9ec870-3d25-43b5-a805-7109751cc722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distance 0.784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Из набора данных word_sim извлеките подвыборку пар слов с индексами 14:114 (нумерация начинается с нуля, правая граница не включается).\n",
        "\n",
        "#Из уже выбранных пар используйте только те, для слов которых находятся векторы на британском корпусе, помеченные как существительные! Иначе удаляйте такую пару из подвыборки.\n",
        "\n",
        "#Вычислите корреляцию Спирмена между оценками схожести выбранных пар слов, полученных в результате работы моделей, и оценками аннотаторов в датасете word_sim.\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "df = pd.read_csv(\"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\",\n",
        "                 sep=\"\\t\", header=None)\n",
        "df.columns = [\"first\", \"second\", \"score\"]\n",
        "df.head(3)\n",
        "\n",
        "delete_count = 0\n",
        "\n",
        "gn_dist, br_dist, scores = [], [], []\n",
        "\n",
        "# 4. Из набора данных word_sim извлеките подвыборку пар слов с индексами 14:114 (нумерация начинается с нуля, правая граница не включается).\n",
        "for row in df.iloc[14:114].iterrows():\n",
        "    w1, w2 = row[1][\"first\"], row[1][\"second\"]\n",
        "    try:\n",
        "        #enter your code here\n",
        "\n",
        "        bk1 = w1.lower() + \"_NOUN\"\n",
        "        bk2 = w2.lower() + \"_NOUN\"\n",
        "\n",
        "        br_dist.append(w_british.similarity(bk1, bk2))\n",
        "\n",
        "        gn_dist.append(w.similarity(w1, w2))\n",
        "\n",
        "        scores.append(row[1][\"score\"])\n",
        "\n",
        "    except KeyError as e:\n",
        "        delete_count += 1\n",
        "        print(e, \"Skipping this word.\")\n",
        "\n",
        "print(\"GN спирман\", spearmanr(gn_dist, scores))\n",
        "print(\"BR спирман\", spearmanr(br_dist, scores))\n",
        "print(\"количество удаленных слов\", delete_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK-FsqGhSCFC",
        "outputId": "bf27df69-5da2-4a29-ff5d-cee62e9fe129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Key 'arafat_NOUN' not present\" Skipping this word.\n",
            "\"Key 'harvard_NOUN' not present\" Skipping this word.\n",
            "\"Key 'mexico_NOUN' not present\" Skipping this word.\n",
            "GN спирман SignificanceResult(statistic=0.6938116658940471, pvalue=3.3231348509522888e-15)\n",
            "BR спирман SignificanceResult(statistic=0.6460421691947137, pvalue=8.94897260473219e-13)\n",
            "количество удаленных слов 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round(0.6938116658940471, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUGr0a5Xz_T8",
        "outputId": "305cf6aa-50e6-4074-d88f-4610b93a40e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.694"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round(0.6460421691947137, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mze8T2wS0JLN",
        "outputId": "abba7d81-0a09-4b58-bc74-48e99c6bef9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.646"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Из набора данных word_sim извлеките подвыборку пар слов с индексами 26:126 (нумерация начинается с нуля, правая граница не включается).\n",
        "\n",
        "#Из уже выбранных пар используйте только те, для слов которых находятся векторы на британском корпусе, помеченные как существительные! Иначе удаляйте такую пару из подвыборки.\n",
        "\n",
        "#Вычислите корреляцию Спирмена между оценками схожести выбранных пар слов, полученных в результате работы моделей, и оценками аннотаторов в датасете word_sim.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\",\n",
        "                 sep=\"\\t\", header=None)\n",
        "df.columns = [\"first\", \"second\", \"score\"]\n",
        "df.head(3)\n",
        "\n",
        "delete_count = 0\n",
        "\n",
        "gn_dist, br_dist, scores = [], [], []\n",
        "\n",
        "for row in df.iloc[26:126].iterrows():\n",
        "    w1, w2 = row[1][\"first\"], row[1][\"second\"]\n",
        "    try:\n",
        "        #enter your code here\n",
        "\n",
        "        bk1 = w1.lower() + \"_NOUN\"\n",
        "        bk2 = w2.lower() + \"_NOUN\"\n",
        "\n",
        "        br_dist.append(w_british.similarity(bk1, bk2))\n",
        "\n",
        "        gn_dist.append(w.similarity(w1, w2))\n",
        "\n",
        "        scores.append(row[1][\"score\"])\n",
        "\n",
        "    except KeyError as e:\n",
        "        delete_count += 1\n",
        "        print(e, \"Skipping this word.\")\n",
        "\n",
        "print(\"GN спирман\", spearmanr(gn_dist, scores))\n",
        "print(\"BR спирман\", spearmanr(br_dist, scores))\n",
        "print(\"количество удаленных слов\", delete_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKTCF1sX57Fx",
        "outputId": "5d91d033-5d4c-49ff-843b-b18de53b4a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Key 'harvard_NOUN' not present\" Skipping this word.\n",
            "\"Key 'mexico_NOUN' not present\" Skipping this word.\n",
            "GN спирман SignificanceResult(statistic=0.7052214812926481, pvalue=5.227025361914796e-16)\n",
            "BR спирман SignificanceResult(statistic=0.6800673363070284, pvalue=1.3508448092503549e-14)\n",
            "количество удаленных слов 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GfvIprGb5871"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}